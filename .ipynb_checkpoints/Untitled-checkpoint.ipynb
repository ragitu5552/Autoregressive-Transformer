{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "391075d3-8c89-4598-a367-808c7cf56080",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4055b7b3-f51a-4180-a730-53b4a1b39b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characte:  1115394\n"
     ]
    }
   ],
   "source": [
    "print('length of dataset in characte: ', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30bf239d-2063-44cb-b482-8ab0048a733e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc4e6c03-28ef-47ab-8018-3d7e3d8882d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd64958-9d2a-4dd3-a87a-1deb986e6ab7",
   "metadata": {},
   "source": [
    "**Will be using Character level Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "110fc434-ce55-4420-8605-df4a73565f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "\n",
    "#Creating a mapping between characters and integers\n",
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[ch] for ch in s]\n",
    "decode = lambda l: ''.join(itos[i] for i in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4bca2c1-69d7-4a7f-92b5-8ebcd7365bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1115394])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing the data\n",
    "\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fafb3d0-dc74-4057-8461-11363d3e160c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b236c3b-7c1c-46b4-944f-e9efe80a730c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003854.6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27e4a165-6c87-44e0-b94c-02b0f7a3c0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1003854]), torch.Size([111540]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and Validation set\n",
    "\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5898dff-fe63-4b28-b85e-d75ecba29641",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = (int)(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "valid_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35b8c5a5-ac14-4842-a14e-4e819d154832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0565dffa-7b24-4596-920b-7f3b217d791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7679e20c-967e-40ca-a748-972f4b250271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([], dtype=torch.int64), target is 18\n",
      "when input is tensor([18]), target is 47\n",
      "when input is tensor([18, 47]), target is 56\n",
      "when input is tensor([18, 47, 56]), target is 57\n",
      "when input is tensor([18, 47, 56, 57]), target is 58\n",
      "when input is tensor([18, 47, 56, 57, 58]), target is 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]), target is 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]), target is 47\n"
     ]
    }
   ],
   "source": [
    "for t in range(block_size):\n",
    "    context = x[:t]\n",
    "    target = x[t]\n",
    "    print(f'when input is {context}, target is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91ab6a3a-529b-4393-ae49-42431ee04708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([452583, 273483, 353744, 504107])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac7caa-8d5c-4b13-a088-708517cdb3df",
   "metadata": {},
   "source": [
    "#Will process multiple samples parallel for computation efficiency as a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "b0bde977-e9a0-4d5e-b483-887fc9bf1c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[39, 47, 52,  1, 59, 52, 41, 59],\n",
      "        [43, 50, 63,  1, 46, 39, 60, 43],\n",
      "        [50, 43,  1, 46, 43, 50, 50,  1],\n",
      "        [53, 59, 50, 42,  1, 63, 53, 59]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[47, 52,  1, 59, 52, 41, 59, 56],\n",
      "        [50, 63,  1, 46, 39, 60, 43,  1],\n",
      "        [43,  1, 46, 43, 50, 50,  1, 51],\n",
      "        [59, 50, 42,  1, 63, 53, 59,  1]])\n",
      "----\n",
      "when input is [39] the target: 47\n",
      "when input is [39, 47] the target: 52\n",
      "when input is [39, 47, 52] the target: 1\n",
      "when input is [39, 47, 52, 1] the target: 59\n",
      "when input is [39, 47, 52, 1, 59] the target: 52\n",
      "when input is [39, 47, 52, 1, 59, 52] the target: 41\n",
      "when input is [39, 47, 52, 1, 59, 52, 41] the target: 59\n",
      "when input is [39, 47, 52, 1, 59, 52, 41, 59] the target: 56\n",
      "when input is [43] the target: 50\n",
      "when input is [43, 50] the target: 63\n",
      "when input is [43, 50, 63] the target: 1\n",
      "when input is [43, 50, 63, 1] the target: 46\n",
      "when input is [43, 50, 63, 1, 46] the target: 39\n",
      "when input is [43, 50, 63, 1, 46, 39] the target: 60\n",
      "when input is [43, 50, 63, 1, 46, 39, 60] the target: 43\n",
      "when input is [43, 50, 63, 1, 46, 39, 60, 43] the target: 1\n",
      "when input is [50] the target: 43\n",
      "when input is [50, 43] the target: 1\n",
      "when input is [50, 43, 1] the target: 46\n",
      "when input is [50, 43, 1, 46] the target: 43\n",
      "when input is [50, 43, 1, 46, 43] the target: 50\n",
      "when input is [50, 43, 1, 46, 43, 50] the target: 50\n",
      "when input is [50, 43, 1, 46, 43, 50, 50] the target: 1\n",
      "when input is [50, 43, 1, 46, 43, 50, 50, 1] the target: 51\n",
      "when input is [53] the target: 59\n",
      "when input is [53, 59] the target: 50\n",
      "when input is [53, 59, 50] the target: 42\n",
      "when input is [53, 59, 50, 42] the target: 1\n",
      "when input is [53, 59, 50, 42, 1] the target: 63\n",
      "when input is [53, 59, 50, 42, 1, 63] the target: 53\n",
      "when input is [53, 59, 50, 42, 1, 63, 53] the target: 59\n",
      "when input is [53, 59, 50, 42, 1, 63, 53, 59] the target: 1\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(1337)\n",
    "\n",
    "# How many independent sequences will we process in parallel\n",
    "batch_size = 4 \n",
    "\n",
    "# Maximum context length for prediction\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "daf854f1-ccf2-4a73-aafb-e1b64d9673e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([619144, 238858, 674174, 567177])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = torch.randint(len(data-block_size), (4, ))\n",
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "27b0f70c-dd43-464f-a732-09be4034b71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"y f, pin ne; 't ieaned d hakeng sthave orce.\\nSCOPampet ke lint t arrsof in hor wiverande o f tit s s montis ndwavet kerat wokyoke thetn CIOf icabreshomerowacheas s, winchis be meny ar ind bo p ukend by fodw he ELorilsathes pin t y mem f YORed ean g.\\nPUEO:\\n3 IZEDutherin udow: iuresth'sedour ald aserswis aveshyoun f ing\\nNUEd one:\\nWhis flay, ICHe\\n\\nI che te bet!\\nS:\\nWe thot atr BRD t and w's\\nAthale reyesttro aravee chacalouse LLI, s\\nThires beet, hirat IINARKInety orifome 'satid his, hengrsofantoro nd ouifardllthe go gre,\\nK:\\nMer'selle.\\nIELOUCAnormardepuf he t\\nMNGRou, nede;\\n\\nbowo tiniseve qu s wimble, ARin-houkionce\\nYoro issar, quroure\\nI wnt n\\n\\n\\nThy g you fomalorontishar tofay ste t\\nVou ginened airme d hen wotor, ig:\\nRDYoos\\n\\nThelo y:\\nSBOFre\\nMPalershiner bofod oredil d;\\nBROlarthin ty f mfoueacr annker as at se ld d Cot nd beat te th, thancut us,\\nLOXEO,\\nA:\\nO: uboke ollyof outt wh if poll o\\nNI muno.\\nICle ICELI:\\nWAMEN:\\nK:\\nMu gshathe?\\nLI it Go byavello me'e s y mes thouchis klapame; wekinerthen re\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking with BigramModel\n",
    "\n",
    "# Lookup table for Bigram\n",
    "N = torch.zeros(vocab_size, vocab_size)\n",
    "for ix, iy in zip(train_data, train_data[1:]):\n",
    "    N[ix, iy] += 1\n",
    "\n",
    "p = N.float()\n",
    "p = p/p.sum(dim=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ab9dfb44-3472-4d37-bfe7-8ed266d4908a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co t keesyove sh we irn he,\n",
      "\n",
      "Burto fouspeg idovouamy.\n",
      "O:\n",
      "Ane athe forou thofow, al INGUCUMir marat pe, ft ofon tistrd stres se me hoda PESI harst CHequsas pe\n",
      "Aned tiout f iopavar I lthokey llis t y Leno alis?\n",
      "Prot thothe mugor f'e ovee hs so,\n",
      "Maths w,\n",
      "ANu 'd ousis tes ayerere k ang hishe! lare!\n",
      "DULA gse nd bun cee y athrs arat!\n",
      "\n",
      "wivarixtllise hary thariorde:\n",
      "Sare bray sted whifr f, onnouive hem;\n",
      "AR: carde vapo farealive t quo tuenee. as ima chs.\n",
      "I mpldot o's\n",
      "Gersety's Cohe.\n",
      "MICal ang IDes, w s s rswares halt uso I fers ty arwime alanaveno'd athepak dersy CI womeryonst gak,\n",
      "BOMad ou s; f f sio \n"
     ]
    }
   ],
   "source": [
    "j = 1\n",
    "text = ''\n",
    "for i in range(600):\n",
    "    j = torch.multinomial(p[j], num_samples=1, replacement=True).item()\n",
    "    text += itos[j]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e5daca-40f0-41e8-80a0-00314477199b",
   "metadata": {},
   "source": [
    "**B, T, C = train_data.shape, where for example B is batch_size, 4 and T is time step/ block_size and C is correspoding info about that element. C is important here for self-attension.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8368e520-c517-4daa-a65c-2cc6b05fc42e",
   "metadata": {},
   "source": [
    "For self-attention, I will add average of all tokens, C feature before the token right now. Which will kind of give me the context of the history. This is a really weak implementation. Might improve on this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a5f64768-6972-4102-b632-5e95ccacddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, 8, 2)\n",
    "B, T, C = x.shape\n",
    "xb = torch.zeros(4, 8, 2)\n",
    "\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        prev = x[b, :t+1]\n",
    "        xb[b, t] = torch.mean(prev, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "5880a8ed-7d9b-42f5-aac2-5722de9d7105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another efficient method for this\n",
    "\n",
    "x = torch.rand(4, 8, 2)\n",
    "B, T, C = x.shape\n",
    "w = torch.tril(torch.ones(8, 8))\n",
    "w = w/w.sum(dim=1, keepdim=True)\n",
    "xb = w @ x  # broadcasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "7ffd2f78-5bc2-4a99-a705-f4e4c1315b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2cdd0763-8f4e-4c94-8be2-183208f52ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72397190-b900-4b23-90eb-ae1333d82037",
   "metadata": {},
   "source": [
    "**Note**: by simply averaging, the past embedding feature values, C. It gives equal weight to all the past tokens. This is what we are now, will be solved using Self-attention model. \n",
    "Every single token will emit two vectors Q, query (what the token is looking for) and K, key (what do i contain). Value, v if you find me interesting here is what i will communicate to you. so v is the thing that aggregated for the purpose of this single head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "89455f54-e901-4bfb-8f4a-a0dd9a175b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e45189f5-c047-40fc-a1ef-2f9c9a89e76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "x = torch.randn(4, 8, 32)\n",
    "B, T, C = x.shape\n",
    "\n",
    "# Single Head attention\n",
    "head_size = 16\n",
    "w1 = torch.randn(C, head_size)\n",
    "Q = x @ w1\n",
    "w2 = torch.randn(C, head_size)\n",
    "k = x @ w2\n",
    "w3 = torch.randn(C, head_size)\n",
    "v = x @ w3\n",
    "# Now the talking part between each other (tokens)\n",
    "w = Q @ k.transpose(-2, -1) * head_size**0.5                                     # Scaled-attention(Q, K, V) = (softmax(Q k.T)/sqrt(dk = head_size)) V\n",
    "\n",
    "# w = torch.tril(torch.ones(T, T))\n",
    "# w = w/w.sum(dim=1, keepdim=True)\n",
    "# w @ x\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "w = w.masked_fill(tril==0, float('-inf'))  # future knowledge won't pass in the current or past tokens\n",
    "w = F.softmax(w, dim=-1)\n",
    "out = w @ v\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "43a8b777-6ab0-4c55-96eb-cb5149f2cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 20\n",
    "head_size = 40\n",
    "block_size = 8\n",
    "token_emb = torch.randn(vocab_size, emb_size)\n",
    "pos_emb = torch.randn(block_size, emb_size)\n",
    "lr = 0.1\n",
    "W1 = torch.randn((emb_size, head_size), requires_grad=True)\n",
    "W2 = torch.randn((emb_size, head_size), requires_grad=True)\n",
    "W3 = torch.randn((emb_size, head_size), requires_grad=True)\n",
    "W4 = torch.randn((head_size, vocab_size), requires_grad=True)\n",
    "tril = torch.tril((torch.ones(T, T)))\n",
    "\n",
    "P = [W1, W2, W3, W4]\n",
    "for p in P:\n",
    "    p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "f03aaa65-5ec1-483f-b29c-f2674d25c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss = []\n",
    "stepi = []\n",
    "for i in range(10000):\n",
    "    xb, yb = get_batch('train')\n",
    "    emb_t = token_emb[xb]\n",
    "    emb_p = pos_emb[torch.arange(block_size)]\n",
    "    emb = emb_t + emb_p\n",
    "    \n",
    "    # applying self-attention\n",
    "    Q = emb @ W1\n",
    "    k = emb @ W2\n",
    "    v = emb @ W3\n",
    "    \n",
    "    w = Q @ k.transpose(-2, -1) / head_size**0.5\n",
    "    w = w.masked_fill(tril==0, float('-inf'))\n",
    "    w = F.softmax(w, dim=-1)\n",
    "    \n",
    "    out = w @ v\n",
    "    \n",
    "    # Linear layer\n",
    "    \n",
    "    logits = out @ W4\n",
    "    B, T, C = logits.shape\n",
    "    logits = logits.view(B*T, C)\n",
    "    yb = yb.view(B*T)\n",
    "    lossi = F.cross_entropy(logits, yb)\n",
    "    loss.append(lossi.item())\n",
    "    stepi.append(i)\n",
    "\n",
    "    # Backward\n",
    "    for p in P:\n",
    "        p.grad = None\n",
    "    lossi.backward()\n",
    "\n",
    "    # Update\n",
    "    for p in P:\n",
    "        p.data += -lr*p.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "aa7e4dbb-78be-4b1a-8727-d9b098b3425b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9823, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "187a3151-3407-4ade-8c35-6f2e6011cefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22595d42990>]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(loss).view(200, -1).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "2a3d88b5-e102-4d0f-84d3-469d2a389cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=23\n",
    "emb_t = token_emb[j]\n",
    "emb_p = pos_emb[torch.arange(block_size)]\n",
    "emb = emb_t + emb_p\n",
    "    \n",
    "Q = emb @ W1\n",
    "k = emb @ W2\n",
    "v = emb @ W3\n",
    "    \n",
    "w = Q @ k.transpose(0, 1) / head_size**0.5\n",
    "#w = w.masked_fill(tril==0, float('-inf'))\n",
    "w = F.softmax(w, dim=-1)\n",
    "out = w @ v\n",
    "\n",
    "logits = out @ W4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "f54ca54b-fa9c-4d80-984c-17a74f7f47ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 8 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[370], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m ix\n",
      "\u001b[1;31mRuntimeError\u001b[0m: a Tensor with 8 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "probs = F.softmax(logits, dim=1)\n",
    "ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "33c26cf9-e1af-4c9e-b363-91c62b9af437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 65])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3532fc-36cb-4a4e-89ae-1a8fbfd6d8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
